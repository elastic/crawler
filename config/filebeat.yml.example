filebeat.inputs:
- type: filestream
  id: crawler-events-filestream
  enabled: true
  paths:
    - "/path/to/opencrawler/crawler_event.log"
  fields:
    type: "event"
  processors:
    - decode_json_fields:
        fields: ["message"]
        target: ""
        overwrite_keys: true
        expand_keys: true

- type: filestream
  id: crawler-system-log-filestream
  enabled: true
  paths:
    - "/path/to/opencrawler/crawler_system.log"
  fields:
    type: "system"
  processors:
    - dissect:
        tokenizer: "[%{@timestamp}] [crawl:%{crawl_id}] [%{crawl_stage}] %{message}"
        target_prefix: ""
        overwrite_keys: true
        trim_values: all

setup.template.enabled: true
setup.template.name: "filebeat"
setup.template.pattern: "filebeat"

setup.template.settings:
  index.number_of_shards: 1
  index.number_of_replicas: 1

logging.level: debug

output.elasticsearch:
  hosts: [""]
  api_key: "id:api_key"
  index: "logs-crawler-%{[fields.type]}" # see https://www.elastic.co/guide/en/fleet/8.17/data-streams.html#data-streams-naming-scheme
